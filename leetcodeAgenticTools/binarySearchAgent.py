from openai import OpenAI
import json
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

client = OpenAI()

# Define my leetcode tools or Tool (tools is a list)

tools = [
    {
        "type": "function",
        "name": "binarySearch",
        "description": "Perform a binary search on a sorted array, when we know the target. To then find the index of the target",
        "parameters": {
            "type": "object",
            "properties": {
                "nums": {
                    "type": "array",
                    "items": {
                        "type": "number"
                    },
                    "description": "A list of numbers sorted"
                },
                "target": {
                    "type": "integer",
                    "description": "the target number we want the location of in the list"
                },
            },
            "required": ["nums", "target"],
        },
    },
]

# Binary Search Function

def binarySearch(nums, target):
        l, r = 0, len(nums) -1
        while l <= r:
            m = (l+r) // 2
            if nums[m] > target:
                r = m -1
            elif nums[m] < target:
                l = m +1
            else:
                return m
        return -1


# Create a running input list we will add to over time
input_list = [
    {"role": "user", "content": "please use binary search to find the index of 9 in this list [-1,0,3,5,9,12] "}
]

# 2. Prompt the model with tools defined
response = client.responses.create(
    model="gpt-5",
    tools=tools,
    input=input_list,
)

# Save function call outputs for subsequent requests
input_list += response.output

for item in response.output:
    if item.type == "function_call":
        if item.name == "binarySearch":
            # 3. Execute the function logic for binarySearch
            args = json.loads(item.arguments)
            targetIndex = binarySearch(args["nums"], args["target"])
            
            # 4. Provide function call results to the model
            input_list.append({
                "type": "function_call_output",
                "call_id": item.call_id,
                "output": json.dumps({
                  "targetIndex": targetIndex
                })
            })

print("Final input:")
print(input_list)

response = client.responses.create(
    model="gpt-5",
    instructions="Respond only with a targetIndex generated by a tool.",
    tools=tools,
    input=input_list,
)

# 5. The model should be able to give a response!
print("Final output:")
print(response.model_dump_json(indent=2))
print("\n" + response.output_text)